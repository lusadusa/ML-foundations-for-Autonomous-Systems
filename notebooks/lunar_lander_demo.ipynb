{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7684ee2a",
   "metadata": {},
   "source": [
    "\n",
    "# LunarLander — REINFORCE (Demo Notebook)\n",
    "\n",
    "This notebook **calls the functions from your code** in\n",
    "`src/reinforcement_learning/lunar_lander/` to train a simple REINFORCE agent\n",
    "and **show the results** (reward curve, quick stats).\n",
    "\n",
    "> Expected repo layout:\n",
    "> `src/reinforcement_learning/lunar_lander/{train.py, eval.py, models.py, reinforce.py, utils.py}`  \n",
    "> Figures are saved under `docs/images/` by `train.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da871dfc-83c6-4bbe-8410-0c631af111d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows-10-10.0.22621-SP0\n",
      "Python exe: C:\\Users\\mtll\\AppData\\Local\\anaconda3\\envs\\ml-foundations\\python.exe\n",
      "Library\\bin in PATH: True\n",
      "KMP_DUPLICATE_LIB_OK: TRUE\n",
      "OMP_NUM_THREADS: 1\n",
      "MKL_NUM_THREADS: 1\n",
      "Spec pygame   -> C:\\Users\\mtll\\AppData\\Local\\anaconda3\\envs\\ml-foundations\\Lib\\site-packages\\pygame\\__init__.py\n",
      "Spec gymnasium-> C:\\Users\\mtll\\AppData\\Local\\anaconda3\\envs\\ml-foundations\\Lib\\site-packages\\gymnasium\\__init__.py\n",
      "Spec Box2D    -> C:\\Users\\mtll\\AppData\\Local\\anaconda3\\envs\\ml-foundations\\Lib\\site-packages\\Box2D\\__init__.py\n",
      "Spec torch    -> C:\\Users\\mtll\\AppData\\Local\\anaconda3\\envs\\ml-foundations\\Lib\\site-packages\\torch\\__init__.py\n",
      "VERSIONS | pygame 2.6.1 | gym 1.0.0 | torch 2.8.0+cpu\n",
      "Torch threads: 1\n"
     ]
    }
   ],
   "source": [
    "# ==== Sanity cell (prima cella del notebook) ====\n",
    "import os, sys, importlib.util, platform\n",
    "\n",
    "# 1) Assicura l’accesso alle DLL dell'env (necessario su Windows per pygame/SDL2)\n",
    "dll_dir = os.path.join(sys.exec_prefix, \"Library\", \"bin\")\n",
    "if os.name == \"nt\" and os.path.isdir(dll_dir):\n",
    "    os.add_dll_directory(dll_dir)\n",
    "\n",
    "# 2) Log di ambiente\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"Python exe:\", sys.executable)\n",
    "print(\"Library\\\\bin in PATH:\", any(\"Library\\\\bin\" in p for p in os.environ.get(\"PATH\",\"\").split(\";\")))\n",
    "print(\"KMP_DUPLICATE_LIB_OK:\", os.environ.get(\"KMP_DUPLICATE_LIB_OK\"))\n",
    "print(\"OMP_NUM_THREADS:\", os.environ.get(\"OMP_NUM_THREADS\"))\n",
    "print(\"MKL_NUM_THREADS:\", os.environ.get(\"MKL_NUM_THREADS\"))\n",
    "\n",
    "# 3) Dove verrebbero caricati i moduli (path)\n",
    "def spec_path(name):\n",
    "    s = importlib.util.find_spec(name)\n",
    "    return getattr(s, \"origin\", None) if s else None\n",
    "\n",
    "print(\"Spec pygame   ->\", spec_path(\"pygame\"))\n",
    "print(\"Spec gymnasium->\", spec_path(\"gymnasium\"))\n",
    "print(\"Spec Box2D    ->\", spec_path(\"Box2D\"))\n",
    "print(\"Spec torch    ->\", spec_path(\"torch\"))\n",
    "\n",
    "# 4) Import \"hard\" con errori espliciti\n",
    "try:\n",
    "    import pygame\n",
    "    import gymnasium as gym\n",
    "    import Box2D\n",
    "    import torch\n",
    "    print(f\"VERSIONS | pygame {pygame.__version__} | gym {gym.__version__} | torch {torch.__version__}\")\n",
    "    print(\"Torch threads:\", torch.get_num_threads())\n",
    "except Exception as e:\n",
    "    import traceback; traceback.print_exc()\n",
    "    raise SystemExit(\n",
    "        \"\\n[FAIL] Import fallito. Se sei su Windows:\\n\"\n",
    "        \"- Assicurati di aprire Jupyter col tuo start_lab.bat (env vars + DLL PATH)\\n\"\n",
    "        \"- Kernel deve essere 'Python (ml-foundations)'\\n\"\n",
    "        \"- pygame/gym/Box2D devono puntare all'env ml-foundations nelle 'Spec' sopra.\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56078f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root resolved to: C:\\Users\\mtll\\Documents\\Personal Rebranding\\ML-Foundations-for-Autonomous-Systems\n",
      "sys.path[0] -> C:\\Users\\mtll\\Documents\\Personal Rebranding\\ML-Foundations-for-Autonomous-Systems\n",
      "lunar_lander path exists: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Try to add the repo root (parent of 'src') to sys.path\n",
    "cwd = Path.cwd()\n",
    "root = cwd\n",
    "# If notebook lives in repo/notebooks/, go one level up\n",
    "if (cwd / \"src\").exists() is False and (cwd.name == \"notebooks\"):\n",
    "    root = cwd.parent\n",
    "\n",
    "if not (root / \"src\").exists():\n",
    "    # walk up until we find 'src' or give up\n",
    "    for p in cwd.parents:\n",
    "        if (p / \"src\").exists():\n",
    "            root = p\n",
    "            break\n",
    "\n",
    "sys.path.insert(0, str(root))\n",
    "print(f\"Repo root resolved to: {root}\")\n",
    "print(\"sys.path[0] ->\", sys.path[0])\n",
    "\n",
    "# Optional: verify the expected package exists\n",
    "expected = root / \"src\" / \"reinforcement_learning\" / \"lunar_lander\"\n",
    "print(\"lunar_lander path exists:\", expected.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69be862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported train/play from src.reinforcement_learning.lunar_lander\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the training and evaluation entry points\n",
    "try:\n",
    "    from src.reinforcement_learning.lunar_lander.train import train\n",
    "    from src.reinforcement_learning.lunar_lander.eval import play\n",
    "    print(\"Imported train/play from src.reinforcement_learning.lunar_lander\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to import train/play. Please check that your files exist:\")\n",
    "    print(\"src/reinforcement_learning/lunar_lander/train.py and eval.py\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c4344b1-c85d-458a-9df5-7e45aa54d26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/50] return=11.0 loss=0.000\n",
      "[20/50] return=18.0 loss=0.000\n",
      "[30/50] return=17.0 loss=0.000\n",
      "[40/50] return=35.0 loss=0.000\n",
      "[50/50] return=19.0 loss=0.000\n"
     ]
    }
   ],
   "source": [
    "returns = train(episodes=50, env_id=\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a7d6f",
   "metadata": {},
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3346b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] return=-49.6 loss=-0.000\n",
      "[20/30] return=-269.9 loss=0.003\n",
      "[30/30] return=-124.2 loss=0.007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30,\n",
       " [np.float64(-143.35930238677554),\n",
       "  np.float64(-160.2385500666097),\n",
       "  np.float64(-265.8496849662847),\n",
       "  np.float64(-64.75937193197998),\n",
       "  np.float64(-124.17923316817432)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# WARNING: training for many episodes can take time.\n",
    "# Start small (e.g., 200–300 episodes) just to produce a visible reward curve.\n",
    "returns = train(episodes=30, env_id=\"LunarLander-v3\", render_mode=None, save_ckpt=False)\n",
    "len(returns), returns[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6233963-0696-46da-8777-4998a40a2658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/mtll/Documents/Personal Rebranding/ML-Foundations-for-Autonomous-Systems/docs/gifs/lunarlander_demo.gif')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.reinforcement_learning.lunar_lander.eval import rollout_frames\n",
    "gif = rollout_frames(episodes=1)  # usa policy random se non hai ancora caricato un checkpoint\n",
    "gif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa167b2f",
   "metadata": {},
   "source": [
    "## Plot training rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215eb149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(returns)), returns, linewidth=1.0)\n",
    "plt.xlabel(\"Episode\"); plt.ylabel(\"Return\")\n",
    "plt.title(\"LunarLander — REINFORCE (training run)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67562cb5",
   "metadata": {},
   "source": [
    "## Display saved figure (if generated by `train.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = Path(root) / \"docs\" / \"images\" / \"lunarlander_rewards.png\"\n",
    "if img.exists():\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(filename=str(img)))\n",
    "else:\n",
    "    print(\"No saved plot found at\", img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d7aa5",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluate the policy (headless)\n",
    "\n",
    "This uses your `eval.py`. If `eval.py` is set to use `render_mode=\"human\"`,\n",
    "it will try to open a window (which notebooks can't show).  \n",
    "For a headless preview inside a notebook, you would need a version of `eval`\n",
    "that creates the environment with `render_mode=\"rgb_array\"` and returns frames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run evaluation for a few episodes. If your eval() uses a GUI window,\n",
    "# consider changing it to 'rgb_array' for notebook previews.\n",
    "try:\n",
    "    play(episodes=3)\n",
    "    print(\"Evaluation run completed.\")\n",
    "except Exception as e:\n",
    "    print(\"Evaluation failed (likely due to render mode). Error:\")\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-foundations)",
   "language": "python",
   "name": "ml-foundations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
